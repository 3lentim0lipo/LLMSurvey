# Experiments



> To reproduce our experiments, we publicly release our experimental code and data here in corrding to the ability.
>
> **We also call for support of computing power for conducting more comprehensive experiments.**



## Code and data

- Language Generation  [experiments](LanguageGeneration).
- Knowledge Utilization  [experiments](KnowledgeUtilization).
- Knowledge Reasoning  [experiments](KnowledgeUtilization).
- Symbolic Reasoning  [experiments](SymbolicReasoning).
- Mathematical Reasoning  [experiments](MathematicalReasoning).
- Human Alignment  [experiments](HumanAlignment).
- Tool Manipulation  [experiments](ToolManipulation).



## Results

Here is the results of instruction-tuning experiments (all in a single-turn conversation) based on the LLaMA (7B) model
under the chat and QA setting. 



![table1](../assets/instruction_tuning_table.png)



Here is the results of evaluation on the eight abilities of LLMs with specially selected tasks.



![table1](../assets/Evaluation_table_1.png)

![table1](../assets/Evaluation_table_2.png)

